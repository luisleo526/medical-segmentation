{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d21841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from dataset import get_transforms\n",
    "\n",
    "with initialize(version_base=None, config_path=\"config\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"root\", overrides=['data=task3'])\n",
    "    \n",
    "transform = get_transforms('train', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fd359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from monai.data import Dataset\n",
    "from monai.data import DataLoader\n",
    "datapaths = []\n",
    "\n",
    "for image_path in glob('D:\\Task03_Liver\\Task03_Liver\\imagesTr\\*'):\n",
    "    datapaths.append({'image':image_path, 'label':image_path.replace('imagesTr', 'labelsTr')})\n",
    "    \n",
    "ds = Dataset(datapaths, transform)\n",
    "dl = DataLoader(ds, num_workers=1, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe3af9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 128, 128, 128]) torch.Size([2, 1, 128, 128, 128])\n",
      "torch.Size([2, 1, 128, 128, 128]) torch.Size([2, 1, 128, 128, 128])\n",
      "torch.Size([2, 1, 128, 128, 128]) torch.Size([2, 1, 128, 128, 128])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n    data = self._loader(d[key], reader)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n    img_array, meta_data = reader.get_data(img)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n    data = self._get_array_data(i)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n    return np.asanyarray(img.dataobj, order=\"C\")\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n    arr = self._get_scaled(dtype=dtype, slicer=())\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n    return array_from_file(\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\nibabel\\volumeutils.py\", line 465, in array_from_file\n    n_read = infile.readinto(data_bytes)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\gzip.py\", line 301, in read\n    return self._buffer.read(size)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\_compression.py\", line 68, in readinto\n    data = self.read(len(byte_view))\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\gzip.py\", line 496, in read\n    uncompress = self._decompressor.decompress(buf, size)\nzlib.error: Error -3 while decompressing data: invalid code lengths set\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n    result = execute_compose(\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n    data = apply_transform(\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x00000284A2631690>\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n    return self._transform(index)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\data\\dataset.py\", line 98, in _transform\n    return apply_transform(self.transform, data_i) if self.transform is not None else data_i\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.compose.Compose object at 0x00000284A2631660>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dl:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n    data = self._loader(d[key], reader)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n    img_array, meta_data = reader.get_data(img)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n    data = self._get_array_data(i)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n    return np.asanyarray(img.dataobj, order=\"C\")\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n    arr = self._get_scaled(dtype=dtype, slicer=())\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n    return array_from_file(\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\nibabel\\volumeutils.py\", line 465, in array_from_file\n    n_read = infile.readinto(data_bytes)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\gzip.py\", line 301, in read\n    return self._buffer.read(size)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\_compression.py\", line 68, in readinto\n    data = self.read(len(byte_view))\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\gzip.py\", line 496, in read\n    uncompress = self._decompressor.decompress(buf, size)\nzlib.error: Error -3 while decompressing data: invalid code lengths set\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n    result = execute_compose(\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n    data = apply_transform(\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x00000284A2631690>\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n    return self._transform(index)\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\data\\dataset.py\", line 98, in _transform\n    return apply_transform(self.transform, data_i) if self.transform is not None else data_i\n  File \"C:\\Users\\HaoLiangWen\\anaconda3\\envs\\medical-segmentation\\lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.compose.Compose object at 0x00000284A2631660>\n"
     ]
    }
   ],
   "source": [
    "for batch in dl:\n",
    "    print(batch['image'].shape, batch['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6f93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:medical-segmentation]",
   "language": "python",
   "name": "conda-env-medical-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
